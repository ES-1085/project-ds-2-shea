```{r load-packages, message = FALSE}
library(tidyverse)
library(ggplot2)
library(broom)
library(readxl)
library(tidytext)
library(dplyr)
library(tm)
library(SnowballC)
library(lubridate)
library(plotly)
library(ggpmisc)
library(htmlwidgets)
```
```{r read_in_data}
Palestine_news_articles <- read_xlsx("../data/Palestine_news_articles.xlsx")
Israel_news_articles <- read_xlsx("../data/israel_news_articles.xlsx")
Gaza_news_articles <- read_xlsx("../data/gaza_news_articles.xlsx")
chat_gpt_article_headlines <- read_xlsx("../data/chat_gpt_data (1).xlsx")
additional_news_data <- read_csv("../data/news_data.csv")
million_news <- read_csv("../data/abcnews-date-text 2 (1).csv")
```
```{r initial_tidy}
tidy_pna <- Palestine_news_articles %>% 
  select("...2", "...3", "...4", "...5") %>% 
  rename("title" = "...2",
         "journal" = "...3",
         "date" = "...4",
         "description" = "...5") %>% 
  filter(!is.na(title)) %>% 
  filter(title != "Title",
         journal != "Journal",
         date != "Date",
         description != "Description") %>% 
  filter(!str_starts(journal, "#")) %>% 
  mutate(keyword = "palestine") %>% 
  distinct()
```
```{r initial_tidy2}
tidy_ina <- Israel_news_articles %>% 
  select("...2", "...3", "...4", "...5") %>% 
  rename("title" = "...2",
         "journal" = "...3",
         "date" = "...4",
         "description" = "...5") %>% 
  filter(!is.na(title)) %>% 
  filter(title != "Title",
         journal != "Journal",
         date != "Date",
         description != "Description") %>% 
  filter(!str_starts(journal, "#")) %>% 
  mutate(keyword = "israel") %>% 
  distinct()
```
```{r initial_tidy3}
tidy_gna <- Gaza_news_articles %>% 
  select("...2", "...3", "...4", "...5") %>% 
  rename("title" = "...2",
         "journal" = "...3",
         "date" = "...4",
         "description" = "...5") %>% 
  filter(!is.na(title)) %>% 
  filter(title != "Title",
         journal != "Journal",
         date != "Date",
         description != "Description") %>% 
  filter(!str_starts(journal, "#")) %>% 
  mutate(keyword = "gaza") %>% 
  distinct()
```

```{r pidf and all_data join}
pidf <- full_join(tidy_pna, tidy_ina)
all_data <- full_join(pidf, tidy_gna)
```

```{r most common journals}
tidy_pna %>%
  count(journal) %>%
  top_n(10, n) %>%
  ggplot(aes(x = reorder(journal, n), y = n)) +
  geom_col() +
  coord_flip() +
  labs(x = "Journal", y = "Frequency") +
  theme_minimal()

tidy_ina %>%
  count(journal) %>%
  top_n(10, n) %>%
  ggplot(aes(x = reorder(journal, n), y = n)) +
  geom_col() +
  coord_flip() +
  labs(x = "Journal", y = "Frequency") +
  theme_minimal()
```

```{r more joining}
inner_join_df <- tidy_pna %>% 
  inner_join(tidy_ina, by = c("title", "journal", "description")) %>% 
  mutate(keyword = "Both") %>% 
  select(title, journal, description, keyword)
```

```{r ^ and create tokenized df}
tokenized_df <- left_join(pidf, inner_join_df, by = c("title", "journal", "description"))

  colnames(tokenized_df)[5] ="keyword"
  colnames(tokenized_df)[6] ="in_both"
  
tokenized_df <- tokenized_df %>% 
  distinct() %>% 
  mutate(in_both = if_else(in_both == "Both", T, F))
```

```{r All_tokens}
sentiments <- get_sentiments("bing")
stop_words <- get_stopwords()

tokenized_df <- tokenized_df %>%
  mutate(Title = title) %>%
  unnest_tokens(word, title) %>%
  anti_join(stop_words)

tokenized_df2 <- tokenized_df %>%
  mutate(Description = description) %>%
  unnest_tokens(word, description) %>%
  anti_join(stop_words)

tokenized_df <- tokenized_df %>%
  mutate(title_or_description = "title")

tokenized_df2 <- tokenized_df2 %>%
  mutate(title_or_description = "description")

colnames(tokenized_df)[3] ="Description"

All_tokens <- tokenized_df %>%
  full_join(tokenized_df2, by = c("journal", "keyword", "in_both", "Title", "word", "Description", "title_or_description"))
  
```

```{r initial_word_frequency_plot}
tokenized_df %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 20) %>%
    ggplot(aes(n, fct_reorder(word, n))) +
    geom_col()

# data$word <- wordStem(data$word)
```

```{r sentiment analysis}
tokenized_df %>% 
  inner_join(sentiments) %>% 
  group_by(sentiment) %>% 
  #filter(keyword == "palestine") %>% 
  count(word, sort = T)

tokenized_df %>% 
  inner_join(sentiments) %>% 
  group_by(sentiment) %>% 
  filter(keyword == "israel") %>% 
  count(word, sort = T)
```

```{r weighted percentage}
pidf %>% 
  unnest_tokens(word, title) %>%
  anti_join(stop_words) %>% 
  group_by(journal) %>% 
  count(word, sort = TRUE) %>% 
  mutate(total_words = sum(n)) %>% 
  mutate(word_percentage = n/total_words) %>% 
  #arrange(desc(word_percentage)) %>% 
  mutate(weighted_percentage = word_percentage * log(total_words)) %>%  # Applying weighting to 
  #arrange(desc(weighted_percentage)) %>% 
  arrange(desc(word_percentage)) %>% 
  #filter(!(word %in% c("palestine", "israel", "gaza")))
  filter(word == "hamas") %>% 
  filter(n >= 100)
  #unnest_tokens(word, description)
```
```{r top 5 in top 5}
# All_tokens$word <- str_replace_all(All_tokens$word, "Â­", "")

All_tokens %>%
  mutate(word = case_when(word %in% c("palestinian", "palestinians") ~"palestine",
                          word %in% c("israeli", "israelis") ~"israel",
                          .default = word)) %>% 
  filter(!is.na(journal)) %>% 
  group_by(word) %>%
  summarize(word_count = n(), journal, Description, keyword, in_both, Title, word, title_or_description) %>%
  ungroup(word) %>% 
  group_by(journal) %>%
  mutate(total_words = n()) %>%
  mutate(word_percentage = word_count/total_words) %>%
  mutate(weighted_percentage = word_percentage * log(total_words)) %>%
  #arrange(desc(weighted_percentage)) %>% 
  filter(total_words > 4600) %>% 
  filter(word_count > 1000) %>% 
  ggplot(aes(x = word_percentage, y = word, fill = journal, colour = journal)) +
  geom_col(position = "fill", stat = "identitiy") +
  labs(title = "Five Most Common Words in Five Most Common Journals")+
  xlab("Relative Word Percentages") +
  ylab("")
```
```{r times of israel vs al javeera}
All_tokens %>%
  mutate(word = case_when(word %in% c("palestinian", "palestinians") ~"palestine",
                          word %in% c("israeli", "israelis") ~"israel",
                          word %in% c("terrorism", "terrorist", "terrorists") ~"terror",
                          word == "west" ~ "west bank", 
                          .default = word)) %>% 
  filter(!is.na(journal)) %>% 
  group_by(word, journal) %>%
  summarize(word_count = n(), journal, Description, keyword, in_both, Title, word, title_or_description) %>%
  ungroup(word) %>% 
  group_by(journal) %>%
  mutate(total_words = n()) %>%
  mutate(word_percentage = word_count/total_words) %>%
  mutate(weighted_percentage = word_percentage * log(total_words)) %>%
  #arrange(desc(weighted_percentage)) %>% 
  filter(journal %in% c("The Times of Israel", "Al Jazeera")) %>% 
  filter(total_words > 5000) %>% 
  #filter(word_count > 500) %>% 
  filter(word %in% c("peace", "terror", "west bank", "palestine", "israel", "gaza", "crisis", "idf", "aggression", "bombing", "genocide", "ceasefire", "occupied", "military")) %>% 
  ggplot(aes(x = word_percentage, y = word, fill = journal, colour = journal)) +
  geom_col(position = "fill") +
  labs(title = "Al Jazeera/Times of Israel Word Frequency Compairison")+
  xlab("Relative Word Percentages") +
  ylab("")
```

```{r palestine israel word compairison}
All_tokens %>% 
  group_by(keyword) %>% 
  count(word, sort = TRUE) %>% 
  filter(word %in% c("palestine", "israel")) %>% 
  ggplot(aes(x = keyword, y = n, fill = word)) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(title = 'Frequency of Words "Israel" and "Palestine"') +
  xlab("News Article Subject") +
  ylab("Frequency") #+
  #facet_wrap(~title_or_description, nrow = 2)
```
```{r gaza west bank word compairison}
All_tokens %>% 
  group_by(keyword, title_or_description) %>% 
  count(word, sort = TRUE) %>% 
  filter(word %in% c("gaza", "west", "bank")) %>% 
  ggplot(aes(x = keyword, y = n, fill = word)) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(title = 'Frequency of Words "Israel" and "Palestine"') +
  xlab("News Article Subject") +
  ylab("Frequency") +
  facet_wrap(~title_or_description, nrow = 2)
```

```{r chat gpt data that I didn't end up using}
gpt <- chat_gpt_article_headlines

pgpt <- chat_gpt_article_headlines %>% 
  select(Palestine_headings)

igpt <- chat_gpt_article_headlines %>% 
  select(Israel_headings)
```

```{r tidying gpt}
pgpt %>% 
  unnest_tokens(word, Palestine_headings) %>% 
  anti_join(stop_words) %>% 
  inner_join(sentiments) %>% 
  group_by(sentiment) %>% 
  count(sentiment, word, sort = T)

igpt %>% 
  unnest_tokens(word, Israel_headings) %>% 
  anti_join(stop_words) %>% 
  inner_join(sentiments) %>% 
  group_by(sentiment) %>% 
  count(sentiment, word, sort = T)
```
```{r distinct gpt}
distinct_igpt <- igpt %>% 
  distinct()

distinct_pgpt <- pgpt %>% 
  distinct()
```

```{r filtering million news}
palestine_million <- million_news %>% 
  filter(str_detect(headline_text, fixed("palestine", ignore_case = T)) |
           str_detect(headline_text, fixed("palestinian", ignore_case = T)) |
           str_detect(headline_text, fixed("gaza", ignore_case = T)) |
           str_detect(headline_text, fixed("west bank", ignore_case = T))) %>% 
  mutate(keyword = "palestine")

israel_million <- million_news %>% 
  filter(str_detect(headline_text, fixed("israel", ignore_case = T))) %>% 
  mutate(keyword = "israel")
           #str_detect(headline_text, fixed("tel aviv", ignore_case = T)))

million_df <- full_join(palestine_million, israel_million, by = c("publish_date", "headline_text", "keyword"))
```

```{r adding additional data}
additional_news_data <- additional_news_data %>%
  rename(title = headline) %>% 
  mutate(source = "additional_news_data")

million_df <- million_df %>%
  rename(title = headline_text,
         date = publish_date) %>% 
  mutate(source = "million_news")

million_df$date <- ymd(million_df$date)

million_df$date <- format(million_df$date, "%d-%m-%Y")

joining <- full_join(additional_news_data, million_df, by = c("title", "date", "source"))
```

```{r merging all real data}
pidf <- pidf %>% 
  mutate(source = "my_scaped_data")

all_real_data <- pidf %>% 
  #select(!date) %>% 
  full_join(joining, by = c("title", "description", "keyword", "source")) %>% 
  rename(date = date.y, untidy_date = date.x) 


tokenized_df3 <- all_real_data %>%
  mutate(Title = title) %>%
  unnest_tokens(word, title) %>%
  anti_join(stop_words)

tokenized_df4 <- all_real_data %>%
  mutate(Description = description) %>%
  unnest_tokens(word, description) %>%
  anti_join(stop_words)

tokenized_df3 <- tokenized_df3 %>%
  mutate(title_or_description = "title")

tokenized_df4 <- tokenized_df4 %>%
  mutate(title_or_description = "description")

colnames(tokenized_df3)[3] ="Description"
colnames(tokenized_df4)[1] ="Title"

all_real_data_tokens <- tokenized_df3 %>%
  full_join(tokenized_df4)
```

```{r most common words coloured by keyword}
all_real_data_tokens %>%
  filter(!is.na(word)) %>% 
  filter(!is.na(keyword)) %>% 
  group_by(keyword) %>%
  filter(keyword == "israel") 

all_real_data_tokens %>%
  filter(!is.na(word)) %>% 
  filter(!is.na(keyword)) %>% 
  group_by(keyword) %>%
  filter(keyword == "palestine")

all_real_data_tokens %>%
  filter(!is.na(word)) %>% 
  filter(!is.na(keyword)) %>% 
  group_by(keyword) %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 20) %>%
    ggplot(aes(n, fct_reorder(word, n), fill = keyword)) +
    geom_col()
```

```{r million news distibution}
all_real_data <- all_real_data %>% 
  mutate(year = str_sub(date, 7, 10)) #%>% 
  #mutate(year = as.numeric(year))

all_real_data_tokens <- all_real_data_tokens %>%
  mutate(year = str_sub(date, 7, 10)) %>%
  mutate(year = as.numeric(year))

all_real_data_tokens %>%
  filter(source == "million_news") %>% 
  filter(!is.na(year)) %>%
  count(year) %>%
  ggplot(aes(x = year, y = n)) +
  geom_col() +
  scale_x_continuous(breaks = seq(2003, 2023, by = 1)) %>% 
  labs(title = "Distribution of Data") +
  xlab("Year") +
  ylab("Count")
```
```{r word palestine use over time in million news}
all_real_data_tokens %>% 
  group_by(year) %>% 
  filter(source == "million_news") %>% 
  filter(!is.na(year), !is.na(word)) %>% 
  count(word, sort = TRUE) %>% 
  mutate(total_words = sum(n)) %>% 
  mutate(word_percentage = n/total_words) %>% 
  filter(word == "palestine") %>% 
  group_by(word) %>% 
  ggplot(aes(x = year, y = word_percentage)) +
  geom_line() +
  scale_x_continuous(breaks = seq(2003, 2024, by = 2)) +
  geom_vline(xintercept = 2009, colour = "red") +
  labs(title = 'Percentage of the Word "Palestine" in Palestine/Israel News Article Headings Over Time') +
  xlab("Year")+
  ylab("Word Percentage")
```
```{r word peace use over time}
all_real_data_tokens %>% 
  group_by(year) %>% 
  #filter(source == "million_news") %>% 
  filter(!is.na(year), !is.na(word)) %>% 
  count(word, sort = TRUE) %>% 
  mutate(total_words = sum(n)) %>% 
  mutate(word_percentage = n/total_words) %>% 
  filter(word == "peace") %>% 
  group_by(word) %>% 
  ggplot(aes(x = year, y = word_percentage)) +
  geom_line() +
  scale_x_continuous(breaks = seq(2003, 2024, by = 1)) +
  geom_vline(xintercept = 2009, colour = "red") +
  geom_vline(xintercept = 2017, colour = "red") +
  labs(title = 'Percentage of the Word "Peace" in Palestine/Israel News Article Headings Over Time') +
  xlab("Year")+
  ylab("Word Percentage")
```


It appears that between between 2009 to 2011 there is a large increase in the use of the word palestine particularly in news articles about palestine. Why? 

2009-2010: Settlement Freeze
U.S. President Barack Obama attempted to revive Israeli-Palestinian peace talks shortly after taking office in 2009. At a speech at Cairo University that year, Obama reiterated his support for a two-state solution.
Why It Matters: As part of a good faith gesture, Israeli Prime Minister Benjamin Netanyahu implemented a settlement freeze, a key Palestinian demand, that lasted 10 months. While talks briefly restarted, Palestinian Authority President Mahmoud Abbas aborted the talks.

No American president ever came into office with a better understanding of the tragic history of the Palestinians or a deeper commitment to help them achieve independence than Obama. In his Cairo speech in April 2009, Obama solemnly pledged to do everything in his power to bring about Palestinian statehood. - Al Jazeera 

Trump was elected in 2017

The 2013â2014 IsraeliâPalestinian peace talks were part of the IsraeliâPalestinian peace process. Direct negotiations between Israel and the Palestinians began on 29 July 2013 following an attempt by United States Secretary of State John Kerry to restart the peace process.

```{r unused/unfinished visualization}
all_real_data_tokens %>% 
  group_by(year) %>% 
  filter(!is.na(year), !is.na(word)) %>% 
  count(word, sort = TRUE) %>% 
  mutate(total_words = sum(n)) %>% 
  mutate(word_percentage = n/total_words) %>% 
  filter(word %in% c("terrorism")) %>% 
  group_by(word) %>% 
  ggplot(aes(x = year, y = word_percentage)) +
  geom_line()+
  scale_x_continuous(breaks = seq(2003, 2023, by = 1)) +
  geom_vline(xintercept = 2009, colour = "red") +
  geom_vline(xintercept = 2017, colour = "red") +
  geom_smooth()

all_real_data_tokens %>% 
  group_by(year, keyword) %>% 
  filter(!is.na(year), !is.na(word)) %>% 
  count(word, sort = TRUE) %>% 
  mutate(total_words = sum(n)) %>% 
  mutate(word_percentage = n/total_words) %>% 
  filter(word %in% c("terrorism")) %>% 
  group_by(word) %>% 
  ggplot(aes(x = year, y = word_percentage, colour = keyword)) +
  geom_point()+
  #geom_smooth()+
  scale_x_continuous(breaks = seq(2003, 2023, by = 1))
```

```{r description title relationship}
All_tokens %>% 
  filter(title_or_description == "title")
All_tokens %>% 
  filter(title_or_description == "description")

All_tokens%>%
  filter(!is.na(word), !is.na(keyword), !is.na(title_or_description)) %>% 
  group_by(keyword, title_or_description) %>%
  count(word, sort = TRUE) %>%
  ggplot(aes(x = n, y = n, colour = keyword)) +
  geom_point()

All_tokens %>%
  filter(!is.na(word), !is.na(keyword), !is.na(title_or_description)) %>% 
  group_by(keyword, title_or_description) %>%
  count(word, sort = TRUE) %>%
  ungroup() %>%
  pivot_wider(names_from = title_or_description, values_from = n, values_fill = 0) %>% 
  ggplot(aes(x = title, y = description)) +
  geom_point()

All_tokens$word <- str_replace_all(All_tokens$word, "Â­", "")
```

```{r model description title relationship}
All_tokens %>%
  filter(!is.na(word), !is.na(keyword), !is.na(title_or_description)) %>% 
  group_by(title_or_description) %>%
  count(word, sort = TRUE) %>%
  ungroup() %>% 
  pivot_wider(names_from = title_or_description, values_from = n, values_fill = 0) %>% 
  mutate(total_description = sum(description)) %>%
  mutate(total_title = sum(title)) %>%
  mutate(title_percentage = title/total_title) %>% 
  mutate(description_percentage = description/total_description) %>% 
  filter(title_percentage > 0.0045, description_percentage > 0.0045) %>% 
  ggplot(aes(x = title_percentage, y = description_percentage, label = word)) +
  geom_point() +
  geom_text(hjust = -0.1, vjust = -0.5, size = 3) + # Adjust position and size of text labels
  labs(x = "Word Count in Title", y = "Word Count in Description", title = "Word Counts Compairison") +
  theme_minimal()

All_tokens %>%
  filter(!is.na(word), !is.na(keyword), !is.na(title_or_description)) %>% 
  group_by(title_or_description) %>%
  count(word, sort = TRUE) %>%
  ungroup() %>% 
  pivot_wider(names_from = title_or_description, values_from = n, values_fill = 0) %>% 
  mutate(total_description = sum(description)) %>%
  mutate(total_title = sum(title)) %>%
  mutate(title_percentage = title/total_title) %>% 
  mutate(description_percentage = description/total_description) %>% 
  filter(title_percentage > 0, description_percentage > 0) %>% 
  ggplot(aes(x = title_percentage, y = description_percentage, label = word)) +
  geom_point(alpha = 0.5) +
  labs(x = "Word Count in Title", y = "Word Count in Description", title = "Word Counts Compairison") +
  theme_minimal() +
  geom_smooth(method = "lm") +
  stat_poly_eq(formula = y ~ x, 
               aes(label = paste(after_stat(rr.label)))) +
  geom_abline(intercept = 0, slope = 1, colour = "red") + 
  scale_x_continuous(breaks = seq(0, 0.06, by = 0.01)) +
  scale_y_continuous(breaks = seq(0, 0.06, by = 0.01)) +
  coord_cartesian(xlim = c(0, 0.06), ylim = c(0, 0.06))

plotly_plot <- All_tokens %>%
  filter(!is.na(word), !is.na(keyword), !is.na(title_or_description)) %>% 
  group_by(title_or_description) %>%
  count(word, sort = TRUE) %>%
  ungroup() %>% 
  pivot_wider(names_from = title_or_description, values_from = n, values_fill = 0) %>% 
  mutate(total_description = sum(description)) %>%
  mutate(total_title = sum(title)) %>%
  mutate(title_percentage = title/total_title) %>% 
  mutate(description_percentage = description/total_description) %>% 
  filter(title_percentage > 0, description_percentage > 0) %>% 
  plot_ly(x = ~title_percentage, y = ~description_percentage, text = ~word) %>%
  add_markers() %>% 
  layout(
    title = "Relationship Between Word Percentages in Title and Description",
    xaxis = list(title = "Percentage in Title"),
    yaxis = list(title = "Percentage in Description")
  )

saveWidget(ggplotly(plotly_plot), file = "plotly_plot.html")
```

```{r title description plotly}
PI_plotly <- All_tokens %>%
  filter(!is.na(word), !is.na(keyword), !is.na(title_or_description)) %>% 
  group_by(keyword) %>%
  count(word, sort = TRUE) %>%
  ungroup() %>% 
  pivot_wider(names_from = keyword, values_from = n, values_fill = 0) %>% 
  mutate(total_description = sum(palestine)) %>%
  mutate(total_title = sum(israel)) %>%
  mutate(title_percentage = israel/total_title) %>% 
  mutate(description_percentage = palestine/total_description) %>% 
  plot_ly(x = ~title_percentage, y = ~description_percentage, text = ~word) %>%
  add_markers() %>% 
  layout(
    title = "Relationship Between Word Percentages in News Articles About Palestine and Israel",
    xaxis = list(title = "Percentage in News Articles About Israel"),
    yaxis = list(title = "Percentage in News Articles About Palestine")
  )

saveWidget(ggplotly(PI_plotly), file = "PI_plotly.html")
```

```{r fix date in scrape data}
 all_real_data_tokens <-  all_real_data_tokens %>% 
  mutate(fixed_date = case_when(
    str_detect(untidy_date, fixed("2023")) ~ 2023,
    str_detect(untidy_date, fixed("2022")) ~ 2022,
    str_detect(untidy_date, fixed("2021")) ~ 2021,
    str_detect(untidy_date, fixed("2020")) ~ 2020,
    str_detect(untidy_date, fixed("2019")) ~ 2019,
    str_detect(untidy_date, fixed("2018")) ~ 2018,
    str_detect(untidy_date, fixed("2017")) ~ 2017,
    str_detect(untidy_date, fixed("2016")) ~ 2016,
    str_detect(untidy_date, fixed("2015")) ~ 2015,
    str_detect(untidy_date, fixed("2014")) ~ 2014,
    str_detect(untidy_date, fixed("2013")) ~ 2013,
    str_detect(untidy_date, fixed("2012")) ~ 2012,
    str_detect(untidy_date, fixed("2011")) ~ 2011,
    str_detect(untidy_date, fixed("2010")) ~ 2010,
    str_detect(untidy_date, fixed("2009")) ~ 2009,
    str_detect(untidy_date, fixed("2008")) ~ 2008,
    str_detect(untidy_date, fixed("2007")) ~ 2007,
    str_detect(untidy_date, fixed("2006")) ~ 2006,
    str_detect(untidy_date, fixed("2005")) ~ 2005,
    str_detect(untidy_date, fixed("2004")) ~ 2004,
    str_detect(untidy_date, fixed("2003")) ~ 2003,
    str_detect(untidy_date, fixed("2002")) ~ 2002,
    str_detect(untidy_date, fixed("2001")) ~ 2001,
    str_detect(untidy_date, fixed("2000")) ~ 2000,
    is.na(untidy_date) ~ NA,
    .default = 2024
  )) %>% 
  mutate(year = if_else(is.na(year), fixed_date, year))
```

```{r mutate year var}
additional_news_data <- additional_news_data %>% 
  mutate(year = str_sub(date, 7, 10))
```

```{r remove non character spaces}
all_real_data_tokens %>% 
  filter(year == 2023) %>% 
  mutate(word = str_squish(word)) %>% 
  filter(word == "israel")
  
  # all_real_data_tokens$word <- gsub("[[:space:]]", "", all_real_data_tokens$word)
  # 
  all_real_data_tokens$word <- str_replace_all(all_real_data_tokens$word, "Â­", "")
```

```{r perecntage word palestine in all data over time}
all_real_data_tokens %>%
  count(year) %>%
  ggplot(aes(x = year, y = n)) +
  geom_col() +
  scale_x_continuous(breaks = seq(2003, 2024, by = 2)) %>% 
  labs(title = "Distribution of Data") +
  xlab("Year") +
  ylab("Count")

all_real_data_tokens %>% 
  filter(!is.na(keyword)) %>% 
  group_by(year, keyword) %>% 
  filter(!is.na(year), !is.na(word)) %>% 
  count(word, sort = TRUE) %>% 
  mutate(total_words = sum(n)) %>% 
  mutate(word_percentage = n/total_words) %>% 
  mutate(word_percentage = n/total_words) %>% 
  filter(word %in% c("palestine")) %>% 
  group_by(word) %>% 
  mutate(Article_Subject = keyword) %>% 
  ggplot(aes(x = year, y = word_percentage, colour = Article_Subject)) +
  #geom_point()+
  geom_smooth(se = F)+
  scale_x_continuous(breaks = seq(2000, 2024, by = 2)) +
  labs(title = 'Frequency of the Word "Palestine" Based on the Subject of the News Article Over Time') +
  xlab("Year") +
  ylab('Percentage of Word "Palestine"')
```

