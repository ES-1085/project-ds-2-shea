```{r load-packages, message = FALSE}
library(tidyverse)
library(broom)
library(readxl)
library(tidytext)
library(dplyr)
library(tm)
library(SnowballC)
library(lubridate)
```

```{r read_in_data}
Palestine_news_articles <- read_xlsx("../data/Palestine_news_articles.xlsx")
Israel_news_articles <- read_xlsx("../data/israel_news_articles.xlsx")
Gaza_news_articles <- read_xlsx("../data/gaza_news_articles.xlsx")
chat_gpt_article_headlines <- read_xlsx("../data/chat_gpt_data (1).xlsx")
```


```{r}
tidy_pna <- Palestine_news_articles %>% 
  select("...2", "...3", "...4", "...5") %>% 
  rename("title" = "...2",
         "journal" = "...3",
         "date" = "...4",
         "description" = "...5") %>% 
  filter(!is.na(title)) %>% 
  filter(title != "Title",
         journal != "Journal",
         date != "Date",
         description != "Description") %>% 
  filter(!str_starts(journal, "#")) %>% 
  mutate(keyword = "palestine") %>% 
  distinct()
```

```{r}
tidy_ina <- Israel_news_articles %>% 
  select("...2", "...3", "...4", "...5") %>% 
  rename("title" = "...2",
         "journal" = "...3",
         "date" = "...4",
         "description" = "...5") %>% 
  filter(!is.na(title)) %>% 
  filter(title != "Title",
         journal != "Journal",
         date != "Date",
         description != "Description") %>% 
  filter(!str_starts(journal, "#")) %>% 
  mutate(keyword = "israel") %>% 
  distinct()
```

```{r}
tidy_gna <- Gaza_news_articles %>% 
  select("...2", "...3", "...4", "...5") %>% 
  rename("title" = "...2",
         "journal" = "...3",
         "date" = "...4",
         "description" = "...5") %>% 
  filter(!is.na(title)) %>% 
  filter(title != "Title",
         journal != "Journal",
         date != "Date",
         description != "Description") %>% 
  filter(!str_starts(journal, "#")) %>% 
  mutate(keyword = "gaza") %>% 
  distinct()
```

```{r}
pidf <- full_join(tidy_pna, tidy_ina)
all_data <- full_join(pidf, tidy_gna)
```

```{r}
tidy_pna %>%
  count(journal) %>%
  top_n(10, n) %>%
  ggplot(aes(x = reorder(journal, n), y = n)) +
  geom_col() +
  coord_flip() +
  labs(x = "Journal", y = "Frequency") +
  theme_minimal()

tidy_ina %>%
  count(journal) %>%
  top_n(10, n) %>%
  ggplot(aes(x = reorder(journal, n), y = n)) +
  geom_col() +
  coord_flip() +
  labs(x = "Journal", y = "Frequency") +
  theme_minimal()

tidy_gna %>%
  count(journal) %>%
  top_n(10, n) %>%
  ggplot(aes(x = reorder(journal, n), y = n)) +
  geom_col() +
  coord_flip() +
  labs(x = "Journal", y = "Frequency") +
  theme_minimal()
```


```{r}
pidf %>%
  group_by(title, journal, description) %>%
  summarize(count_of_string = n()) #%>% 
  # mutate(count_of_string = n) %>%
  #mutate(keyword = if_else(count_of_string == 1, keyword, "Both"))
```

```{r}
inner_join_df <- tidy_pna %>% 
  inner_join(tidy_ina, by = c("title", "journal", "description")) %>% 
  mutate(keyword = "Both") %>% 
  select(title, journal, description, keyword)
```

```{r}
tokenized_df <- left_join(pidf, inner_join_df, by = c("title", "journal", "description"))

  colnames(tokenized_df)[5] ="keyword"
  colnames(tokenized_df)[6] ="in_both"
  colnames(tokenized_df)[3] ="Description"
  
tokenized_df <- tokenized_df %>% 
  distinct() %>% 
  mutate(in_both = if_else(in_both == "Both", T, F))
```

```{r}
sentiments <- get_sentiments("bing")
stop_words <- get_stopwords()

# tokenized_df <- tokenized_df %>%
#   mutate(Title = title) %>%
#   unnest_tokens(word, title) %>%
#   anti_join(stop_words) 

# tokenized_df2 <- tokenized_df %>%
#   mutate(Description = description) %>%
#   unnest_tokens(word, description) %>%
#   anti_join(stop_words) 

tokenized_df <- tokenized_df %>% 
  mutate(title_or_description = "title")

tokenized_df2 <- tokenized_df2 %>% 
  mutate(title_or_description = "description")

All_tokens <- tokenized_df %>% 
  full_join(tokenized_df2, by = c("journal", "date", "keyword", "in_both", "Title", "word", "Description", "title_or_description"))
  
```

```{r}
tokenized_df %>%
    count(word, sort = TRUE) %>%
    slice_max(n, n = 20) %>%
    ggplot(aes(n, fct_reorder(word, n))) +
    geom_col()

# data$word <- wordStem(data$word)
```

```{r}
tokenized_df %>% 
  inner_join(sentiments) %>% 
  group_by(sentiment) %>% 
  filter(in_both == F) %>% 
  filter(keyword == "palestine") %>% 
  count(sentiment, word, sort = T) %>% 
  filter(sentiment == "positive")

tokenized_df %>% 
  inner_join(sentiments) %>% 
  group_by(sentiment) %>% 
  filter(in_both == F) %>% 
  filter(keyword == "israel") %>% 
  count(sentiment, word, sort = T) %>% 
  filter(sentiment == "positive")
```

```{r}
all_data %>% 
  unnest_tokens(word, title) %>%
  anti_join(stop_words) %>% 
  group_by(journal) %>% 
  count(word, sort = TRUE) %>% 
  mutate(total_words = sum(n)) %>% 
  mutate(word_percentage = n/total_words) %>% 
  #arrange(desc(word_percentage)) %>% 
  mutate(weighted_percentage = word_percentage * log(total_words)) %>%  # Applying weighting to 
  #arrange(desc(weighted_percentage)) %>% 
  arrange(desc(word_percentage)) %>% 
  #filter(!(word %in% c("palestine", "israel", "gaza")))
  filter(word == "hamas") %>% 
  filter(n >= 10)
  #unnest_tokens(word, description)
```
```{r}
All_tokens %>% 
  group_by(word) %>%  
  summarize(word_count = n(), journal, date, Description, keyword, in_both, Title, word, title_or_description) # %>% 
#   mutate(total_words = sum(n)) %>% 
#   mutate(word_percentage = n/total_words) %>% 
#   mutate(weighted_percentage = word_percentage * log(total_words)) %>%
#   arrange(desc(word_percentage)) %>% 
#   group_by(word)
```

```{r}
tokenized_df %>% 
  group_by(keyword) %>% 
  count(word, sort = TRUE) %>% 
  filter(word %in% c("palestine", "israel")) %>% 
  ggplot(aes(x = keyword, y = n, fill = word)) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(title = "Words Frequency in Title")

tokenized_df2 %>% 
  group_by(keyword) %>% 
  count(word, sort = TRUE) %>% 
  filter(word %in% c("palestine", "israel")) %>% 
  ggplot(aes(x = keyword, y = n, fill = word)) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(title = "Words Frequency in Description")
```



```{r}
All_tokens %>% 
  group_by(keyword, title_or_description) %>% 
  count(word, sort = TRUE) %>% 
  filter(word %in% c("palestine", "israel")) %>% 
  ggplot(aes(x = keyword, y = n, fill = word)) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(title = 'Frequency of Words "Israel" and "Palestine"') +
  xlab("News Article Subject") +
  ylab("Frequency") +
  facet_wrap(~title_or_description, nrow = 2)
```
```{r}
All_tokens %>% 
  group_by(keyword, title_or_description) %>% 
  count(word, sort = TRUE) %>% 
  filter(word %in% c("gaza", "west", "bank")) %>% 
  ggplot(aes(x = keyword, y = n, fill = word)) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(title = 'Frequency of Words "Israel" and "Palestine"') +
  xlab("News Article Subject") +
  ylab("Frequency") +
  facet_wrap(~title_or_description, nrow = 2)
```

```{r}
gpt <- chat_gpt_article_headlines

pgpt <- chat_gpt_article_headlines %>% 
  select(Palestine_headings)

igpt <- chat_gpt_article_headlines %>% 
  select(Israel_headings)
```

```{r}
pgpt %>% 
  unnest_tokens(word, Palestine_headings) %>% 
  anti_join(stop_words) %>% 
  inner_join(sentiments) %>% 
  group_by(sentiment) %>% 
  count(sentiment, word, sort = T)

igpt %>% 
  unnest_tokens(word, Israel_headings) %>% 
  anti_join(stop_words) %>% 
  inner_join(sentiments) %>% 
  group_by(sentiment) %>% 
  count(sentiment, word, sort = T)
```
```{r}
distinct_igpt <- igpt %>% 
  distinct()

distinct_pgpt <- pgpt %>% 
  distinct()
```

```{r}
palestine_million <- abcnews_date_text_2_1_ %>% 
  filter(str_detect(headline_text, fixed("palestine", ignore_case = T)) |
           str_detect(headline_text, fixed("palestinian", ignore_case = T)) |
           str_detect(headline_text, fixed("gaza", ignore_case = T)) |
           str_detect(headline_text, fixed("west bank", ignore_case = T))) %>% 
  mutate(keyword = "palestine")

israel_million <- abcnews_date_text_2_1_ %>% 
  filter(str_detect(headline_text, fixed("israel", ignore_case = T))) %>% 
  mutate(keyword = "palestine")
           #str_detect(headline_text, fixed("tel aviv", ignore_case = T)))

million_df <- full_join(palestine_million, israel_million, by = c("publish_date", "headline_text", "keyword"))
```

```{r}
# news_data <- news_data %>% 
#   rename(title = headline)

# million_df <- million_df %>%
#   rename(title = headline_text,
#          date = publish_date)
# 
# million_df$date <- ymd(million_df$date)
# 
# million_df$date <- format(million_df$date, "%d-%m-%Y")
```

```{r}
joining <- full_join(news_data, million_df, by = c("title", "date"))



all_real_data <- pidf %>% 
  #select(!date) %>% 
  full_join(joining, by = c("title", "description", "keyword")) %>% 
  rename(date = date.y, untidy_date = date.x) 
```

